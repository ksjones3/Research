{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa37892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, particleText):\n",
    "        \n",
    "        #Get our list of quantities for the particle\n",
    "        particleInfo = particleText.split(\",\")\n",
    "        \n",
    "        #Define our particle quantities\n",
    "        self.obj = particleInfo[0]\n",
    "        self.E = float(particleInfo[1])\n",
    "        self.pt = float(particleInfo[2])\n",
    "        self.eta = float(particleInfo[3])\n",
    "        self.phi = float(particleInfo[4])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"(obj: \" + self.obj + \", E: \" + str(self.E) + \", pt: \" + str(self.pt) + \", eta: \" + str(self.eta) + \", phi: \" +str(self.phi) + \")\"\n",
    "    \n",
    "    def getQuantity(self, quantityType):\n",
    "        \n",
    "        if quantityType == \"E\":\n",
    "            return self.E\n",
    "        \n",
    "        elif quantityType == \"pt\":\n",
    "            return self.pt\n",
    "        \n",
    "        elif quantityType == \"eta\":\n",
    "            return self.eta\n",
    "        \n",
    "        elif quantityType == \"phi\":\n",
    "            return self.phi\n",
    "\n",
    "        else:\n",
    "            print(\"Error: Invalid quantity type\")\n",
    "            return 0.0\n",
    "        \n",
    "    __repr__=__str__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from random import shuffle\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error\n",
    "from keras.losses import KLDivergence as KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkJets(obj):\n",
    "    return obj in [\"j\", \"b\"]\n",
    "\n",
    "def checkLeptons(obj):\n",
    "    return obj in [\"e-\", \"e+\", \"m-\", \"m+\"]\n",
    "\n",
    "def checkPhotons(obj):\n",
    "    return obj==\"g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cf43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeParticleList(eventInfo):\n",
    "    \n",
    "    #total number of datapoints in the line\n",
    "    length = len(eventInfo)\n",
    "    \n",
    "    particleList = []\n",
    "    \n",
    "    #Increment over all of the particles in the line\n",
    "    for i in range(5, length):\n",
    "        \n",
    "        #Get the text for the particle\n",
    "        particleText = eventInfo[i]\n",
    "        \n",
    "        #Make sure that it is actually information for the particle\n",
    "        if particleText != \"\" and particleText != \"\\n\":\n",
    "            \n",
    "            particle = Particle(particleText)\n",
    "            \n",
    "            particleList.append(particle)\n",
    "    \n",
    "    return particleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff67730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEvent(line, signal):\n",
    "    \n",
    "    eventInfo = line.split(\";\")\n",
    "    \n",
    "    eventID = eventInfo[0]\n",
    "    processID = eventInfo[1]\n",
    "    eventWeight = float(eventInfo[2])\n",
    "    MET = float(eventInfo[3])\n",
    "    METPhi = float(eventInfo[4])\n",
    "    \n",
    "    signal = float(signal)\n",
    "    \n",
    "    particleList = makeParticleList(eventInfo)\n",
    "    \n",
    "    crossSection = 1.0\n",
    "    \n",
    "    event = {\n",
    "        \"eventID\" : eventID,\n",
    "        \"processID\" : processID,\n",
    "        \"eventWeight\" : eventWeight,\n",
    "        \"MET\" : MET,\n",
    "        \"METPhi\" : METPhi,\n",
    "        \"particleList\" : particleList,\n",
    "        \"crossSection\" : crossSection,\n",
    "        \"signal\" : signal\n",
    "    }\n",
    "    \n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be29f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSignalCrossSection(event, length):\n",
    "    \n",
    "    eventWeight = event[\"eventWeight\"]\n",
    "    \n",
    "    crossSection = eventWeight*length\n",
    "    \n",
    "    return crossSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07452df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateBackgroundCrossSection(length, luminosity):\n",
    "    \n",
    "    crossSection = length/luminosity\n",
    "    \n",
    "    return crossSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCrossSection(event, length, luminosity, signal):\n",
    "    if signal:\n",
    "        return calculateSignalCrossSection(event, length)\n",
    "    else:\n",
    "        return calculateBackgroundCrossSection(length, luminosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3faef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataList(filePath, signal, luminosity = 1.0):\n",
    "    \n",
    "    file = open(filePath, \"r\")\n",
    "    \n",
    "    dataList = []\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "        event = makeEvent(line, signal)\n",
    "        \n",
    "        dataList.append(event)\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    length = float(len(dataList))\n",
    "    \n",
    "    for event in dataList:\n",
    "        \n",
    "        event[\"crossSection\"] = calculateCrossSection(event, length, luminosity, signal)\n",
    "    \n",
    "    \n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeParticleVectors(event):\n",
    "    \n",
    "    particleVectors = []\n",
    "    particleList = event[\"particleList\"]\n",
    "    length = len(particleList)\n",
    "    \n",
    "    #jets = []\n",
    "    #leptons = []\n",
    "    \n",
    "    #for particle in particleList:\n",
    "        #if checkJets(particle.obj):\n",
    "            #jets.append(particle)\n",
    "        #elif checkLeptons(particle.obj):\n",
    "            #leptons.append(particle)\n",
    "    \n",
    "    #jetNumber = len(jets)\n",
    "    #leptonNumber = len(leptons)\n",
    "    \n",
    "    #for i in range(0, 6):\n",
    "        #if i < jetNumber:\n",
    "            #jet = jets[i]\n",
    "            #particleVectors.append(jet.pt)\n",
    "            #particleVectors.append(jet.eta)\n",
    "            #particleVectors.append(jet.phi)\n",
    "            #particleVectors.append(jet.E)\n",
    "        #else:\n",
    "            #for j in range(0, 4):\n",
    "                #particleVectors.append(0.0)\n",
    "    \n",
    "    #for i in range(0, 2):\n",
    "        #if i < leptonNumber:\n",
    "            #lepton = leptons[i]\n",
    "            #particleVectors.append(lepton.pt)\n",
    "            #particleVectors.append(lepton.eta)\n",
    "            #particleVectors.append(lepton.phi)\n",
    "            #particleVectors.append(lepton.E)\n",
    "        #else:\n",
    "            #for j in range(0, 4):\n",
    "                #particleVectors.append(0.0)\n",
    "        \n",
    "    for i in range(0, 8):\n",
    "        if i < length:\n",
    "            particle = particleList[i]\n",
    "            particleVectors.append(particle.pt)\n",
    "            particleVectors.append(particle.eta)\n",
    "            particleVectors.append(particle.phi)\n",
    "            particleVectors.append(particle.E)\n",
    "        else:\n",
    "            for n in range(0, 4):\n",
    "                particleVectors.append(0.0)\n",
    "    \n",
    "    return particleVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(data):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaledData = scaler.fit_transform(data)\n",
    "    return scaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac8ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a0d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeArea(hist, bin_edges):\n",
    "    \n",
    "    bin_size = bin_edges[1] - bin_edges[0]\n",
    "    integral = sum(hist) * bin_size\n",
    "    normalizedCount = (1.0/integral) * hist\n",
    "    \n",
    "    return normalizedCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5feeba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistogram(y_Predict, x_Predict, numBins):\n",
    "    y_hist, bin_edges = np.histogram(y_Predict, bins=numBins)\n",
    "    normalizedYCount = normalizeArea(y_hist, bin_edges)\n",
    "    plt.step(bin_edges[1:], normalizedYCount, label=\"Signal\")\n",
    "    x_hist, bin_edges = np.histogram(x_Predict, bins=numBins)\n",
    "    normalizedXCount = normalizeArea(x_hist, bin_edges)\n",
    "    plt.step(bin_edges[1:], normalizedXCount, label=\"Background\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_Functions:\n",
    "    def __init__(self, beta):\n",
    "        self.beta = beta\n",
    "    \n",
    "    def custom_loss_function(y_true, y_pred):\n",
    "        return (1.0-self.beta)*mean_squared_error(y_true, y_pred) + self.beta*KL(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "def makeVAE(beta, intermediate_dim, data):\n",
    "    \n",
    "    original_dim = data.shape[1]\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "    \n",
    "    # Create encoder\n",
    "    encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "    \n",
    "    functions = LossFunctions(beta)\n",
    "    custom_Loss_Function = functions.custom_loss_function\n",
    "    \n",
    "    vae.compile(optimizer = \"adam\", loss = custom_loss_function)\n",
    "    \n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4170ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDynamicParticleList(particleList):\n",
    "    \n",
    "    dynamicParticleList = []\n",
    "    \n",
    "    for particle in particleList:\n",
    "        \n",
    "        jet = 0\n",
    "        lepton = 0\n",
    "        photon = 0\n",
    "        \n",
    "        obj = particle.obj\n",
    "        \n",
    "        if checkJets(obj):\n",
    "            jet = 1\n",
    "        elif checkLeptons(obj):\n",
    "            lepton = 1\n",
    "        elif checkPhotons(obj):\n",
    "            photon = 1\n",
    "        \n",
    "        dynamicParticle = (jet, lepton, photon, particle.pt, particle.E, particle.eta, particle.phi)\n",
    "        dynamicParticleList.append(dynamicParticle)\n",
    "        \n",
    "    return dynamicParticleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDynamicData(dataList):\n",
    "    \n",
    "    dynamicData = []\n",
    "    dynamicYTrue = []\n",
    "    \n",
    "    for event in dataList:\n",
    "        \n",
    "        particleList = makeDynamicParticleList(dataList[\"particleList\"])\n",
    "        dynamicEvent = [event[\"MET\"], event[\"METPhi\"], particleList]\n",
    "        dynamicData.append(dynamicEvent)\n",
    "        dynamicYTrue.append(event[\"signal\"])\n",
    "    \n",
    "    return dynamicData, dynamicYTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e54e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countParticles(dataList):\n",
    "    \n",
    "    maxNumJets = 0\n",
    "    maxNumLeptons = 0\n",
    "    maxNumPhotons = 0\n",
    "    \n",
    "    for event in dataList:\n",
    "        \n",
    "        numJets = 0\n",
    "        numPhotons = 0\n",
    "        numLeptons = 0\n",
    "        \n",
    "        for particle in dataList[\"particleList\"]:\n",
    "            \n",
    "            obj = particle.obj\n",
    "            \n",
    "            if checkJets(obj):\n",
    "                numJets = numJets + 1\n",
    "            elif checkLeptons(obj):\n",
    "                numLeptons = numLeptons + 1\n",
    "            elif checkPhotons(obj):\n",
    "                numPhotons = numPhotons +1\n",
    "        \n",
    "        if numJets > maxNumJets:\n",
    "            maxNumJets = numJets\n",
    "        if numLeptons > maxNumLeptons:\n",
    "            maxNumLeptons = numLeptons\n",
    "        if numPhotons > maxNumPhotons:\n",
    "            maxNumPhotons = numPhotons\n",
    "    \n",
    "    return maxNumJets, maxNumLeptons, maxNumPhotons\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c06688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParticles(particleList):\n",
    "    \n",
    "    jets = []\n",
    "    leptons = []\n",
    "    photons = []\n",
    "    \n",
    "    for particle in particleList:\n",
    "        \n",
    "        obj = particle.obj\n",
    "        \n",
    "        if checkJets(obj):\n",
    "            jets.append(particle)\n",
    "        elif checkLeptons(obj):\n",
    "            leptons.append(particle)\n",
    "        elif checkPhotons(obj):\n",
    "            photons.append(particle)\n",
    "    \n",
    "    return jets, leptons, photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatStaticData(dataList):\n",
    "    \n",
    "    maxNumJets, maxNumLeptons, maxNumPhotons = countParticles(dataList)\n",
    "    \n",
    "    staticData = []\n",
    "    staticYTrue = []\n",
    "    \n",
    "    for event in dataList:\n",
    "        \n",
    "        staticEvent = []\n",
    "        staticEvent.append(event[\"MET\"])\n",
    "        staticEvent.append(event[\"METPhi\"])\n",
    "        jets, leptons, photons = getParticles(event[\"particleList\"])\n",
    "        \n",
    "        for jet in jets:\n",
    "            \n",
    "            staticEvent.append(jet.pt)\n",
    "            staticEvent.append(jet.E)\n",
    "            staticEvent.append(jet.eta)\n",
    "            staticEvent.append(jet.phi)\n",
    "            \n",
    "        if len(jets) < maxNumJets:\n",
    "            for i in range(len(jets), maxNumJets):\n",
    "                for j in range(0, 4):\n",
    "                    staticEvent.append(0.0)\n",
    "                    \n",
    "        for lepton in leptons:\n",
    "            \n",
    "            staticEvent.append(lepton.pt)\n",
    "            staticEvent.append(lepton.E)\n",
    "            staticEvent.append(lepton.eta)\n",
    "            staticEvent.append(lepton.phi)\n",
    "            \n",
    "        if len(leptons) < maxNumLeptons:\n",
    "            for i in range(len(leptons), maxNumLeptons):\n",
    "                for j in range(0, 4):\n",
    "                    staticEvent.append(0.0)\n",
    "        \n",
    "        for photon in photons:\n",
    "            \n",
    "            staticEvent.append(photon.pt)\n",
    "            staticEvent.append(photon.E)\n",
    "            staticEvent.append(photon.eta)\n",
    "            staticEvent.append(photon.phi)\n",
    "            \n",
    "        if len(photons) < maxNumPhotons:\n",
    "            for i in range(len(photons), maxNumPhotons):\n",
    "                for j in range(0, 4):\n",
    "                    staticEvent.append(0.0)\n",
    "        staticData.append(staticEvent)\n",
    "        staticYTrue.append(event[\"signal\"])\n",
    "    \n",
    "    return staticData, staticYTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4a0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroundDataList = makeDataList(\"Data/training_files/training_files/chan1/background_chan1_7.79.csv\", False, luminosity = 7.79)\n",
    "signalDataList = makeDataList(\"Data/training_files/training_files/chan1/glgl1400_neutralino1100_chan1.csv\", True)\n",
    "length = len(signalDataList)\n",
    "testDataList = signalDataList+backgroundDataList[:length]\n",
    "trainingDataList = backgroundDataList[length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1daba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "staticTrainingData, dummy = formatStaticData(trainingDataList)\n",
    "staticTestData, staticYTrue = formatStaticData(testDataList)\n",
    "dynamicTrainingData, dummy = formatTrainingData(trainingDataList)\n",
    "dynamicTestData, dynamicYTrue = formatTestData(testDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [1.0E-6, 1.0E-3, 0.1, 0.5, 0.8, 0.999, 1.0]\n",
    "zs = [5, 8, 13, 21, 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAEDict = {}\n",
    "\n",
    "for beta in betas:\n",
    "    for z in zs:\n",
    "        staticVae = makeVAE(beta, z, staticTrainingData)\n",
    "        staticHistory = staticVae.fit(staticTrainingData, staticTrainingData, epochs=100,\n",
    "               batch_size=125,\n",
    "               shuffle='batch',\n",
    "               validation_split=0.1)\n",
    "        staticPredict = staticVae.predict(staticTestData)\n",
    "        staticVaeDict = {\n",
    "            \"VAE\": staticVae,\n",
    "            \"history\": staticHistory,\n",
    "            \"predict\": staticPredict\n",
    "        }\n",
    "        VAEDict[\"static\"+str(beta)+\"beta\"+str(z)+\"z\"] = staticVaeDict\n",
    "        \n",
    "        dynamicVae = makeVAE(beta, z, dynamicTrainingData)\n",
    "        dynamicHistory = dynamicVae.fit(dynamicTrainingData, dynamicTrainingData, epochs=100,\n",
    "               batch_size=125,\n",
    "               shuffle='batch',\n",
    "               validation_split=0.1)\n",
    "        dynamicPredict = dynamicVae.predict(dynamicTestData)\n",
    "        dynamicVaeDict = {\n",
    "            \"VAE\" : dynamicVae,\n",
    "            \"history\": dynamicHistory,\n",
    "            \"predict\": dynamicPredict\n",
    "        }\n",
    "        VAEDict[\"dynamic\"+str(beta)+\"beta\"+str(z)+\"z\"] = dynamicVaeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b71608",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=autoencoderBackgroundData.shape[1]\n",
    "\n",
    "input_vec = Input(shape =(input_dim,))\n",
    "\n",
    "encoded = Dense(34, activation='relu')(input_vec)\n",
    "encoded = Dense(200, activation='tanh')(encoded)\n",
    "encoded = Dense(200, activation='tanh')(encoded)\n",
    "encoded = Dense(20, activation='tanh')(encoded)\n",
    "mean = Dense(34, )\n",
    "decoded = Dense(10, activation='tanh')(encoded)\n",
    "decoded = Dense(20, activation='tanh')(decoded)\n",
    "decoded = Dense(200, activation='tanh')(decoded)\n",
    "decoded = Dense(200, activation='tanh')(decoded)\n",
    "decoded = Dense(input_dim, activation='relu')(decoded)\n",
    "\n",
    "autoencoder=Model(input_vec, decoded)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer=\"adam\",\n",
    "                    loss=\"mean_squared_error\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b802f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00005, patience=20)\n",
    "\n",
    "history=autoencoder.fit(autoencoderBackgroundData, autoencoderBackgroundData, epochs=100,\n",
    "               batch_size=125,\n",
    "               shuffle='batch',\n",
    "               validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Predict = calculateAutoencoderError(X_Test, autoencoder)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_Test, y_Predict)\n",
    "                        \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b508679",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroundAutoencoderData = formatAutoencoderData(backgroundDataList)[VarNames]\n",
    "signalAutoencoderData = formatAutoencoderData(signalDataList)[VarNames]\n",
    "x_Predict = calculateAutoencoderError(backgroundAutoencoderData, autoencoder)\n",
    "y_Predict = calculateAutoencoderError(signalAutoencoderData, autoencoder)\n",
    "\n",
    "plotHistogram(y_Predict, x_Predict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e26608",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(history.history[\"loss\"])),history.history[\"loss\"],label=\"Training Loss\")\n",
    "plt.plot(range(len(history.history[\"val_loss\"])),history.history[\"val_loss\"],label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortedData = autoencoder.predict(X_Test)\n",
    "y_Predict = []\n",
    "X_Test_numpy = X_Test.to_numpy()\n",
    "for i in range(0, len(distortedData)):\n",
    "    X = X_Test_numpy[i]\n",
    "    Y = distortedData[i]\n",
    "    predict = mean_squared_error(X, Y)\n",
    "    y_Predict.append(predict)\n",
    "    \n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_Test, y_Predict)\n",
    "                        \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ebf46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
